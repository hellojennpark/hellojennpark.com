---
title: "Building Withsy: Why I Created Yet Another AI Chat Platform (And What I Learned)"
description: "A candid look at building a personal AI chat platform, from solving UI frustrations to achieving 97% performance improvements, and the honest lessons about product-market fit in a crowded AI landscape."
tags: ["project", "withsy", "ai", "chat interface", "product development", "next.js", "performance optimization"]
date: "2025-05-09"
---


## The Itch That Needed Scratching

Like many developers, I found myself using multiple AI chat platforms daily—ChatGPT, Claude, Gemini, Perplexity. They're all incredible tools, but small frustrations kept piling up. Why couldn't I customize the theme like I do with Slack? Why did conversations feel so impersonal with generic model names? Why couldn't I see or control the prompts being applied to my conversations?

So I did what any developer would do: I built my own AI chat platform called **Withsy**.

## The Reality Check

Here's the uncomfortable truth I discovered after building Withsy: **it solves problems that matter to me, but may not provide enough value for most users to switch**. With ChatGPT, Claude, Gemini, and Perplexity all offering generous free tiers, convincing someone to try yet another AI platform is a tough sell.

But the journey taught me valuable lessons about user experience, performance optimization, and product-market fit that I want to share.

## Core Features: Solving Real Frustrations

### 1. Personalized Chat Experience

**The Problem**: Generic, sterile interfaces that feel more like debugging tools than conversation partners.

**The Solution**: 
- **Custom themes** inspired by Slack's customization options. Just like I change Slack to blue themes in summer and red in winter for that psychological refresh, Withsy lets users personalize their chat environment
- **Custom model nicknames** instead of seeing "gemini-2.0-flash-exp", users can set friendly names like "gem" or whatever feels natural
- **Custom character avatars** for each model, because visual identity matters in building rapport—just like profile pictures in online communities

This wasn't about the AI models themselves, but about making the *platform* feel personal. Statistics show people use AI more for companionship and emotional support than originally expected, so why not make it feel more human?

### 2. Complete Prompt Transparency

**The Problem**: Hidden system prompts that make AI responses unpredictable and sometimes frustratingly sycophantic.

**The Solution**: Full visibility and control over prompts applied to conversations.

Users can:
- Set default prompts for all chats
- Create and manage prompt templates for specific use cases
- See exactly what prompts are being applied (no hidden wrappers)

This isn't just about control—it's about preventing bias and misinformation. When AI platforms apply invisible prompts "for personalization," users can unknowingly receive skewed information. Transparency helps users understand why they're getting certain responses.

### 3. Conversation Branching

**The Problem**: When an AI provides three different approaches to a problem, asking follow-up questions about each one pollutes the context and leads to confused responses.

**The Solution**: Branch functionality that lets users fork conversations at any point.

Instead of creating separate chats and losing track of the original context, users can explore different conversation paths while maintaining clear relationships between discussions.

**Technical Implementation**: I separated the data model into `chat` and `branch` entities. Chats maintain lists of their branches, branches reference their origin chat, and the API serves only the relevant message context up to the branch point.

### 4. Smart Chat Management

**The Problem**: Poor search functionality and no way to organize important conversations.

**The Solution**: 
- Star/bookmark system to pin important chats
- Message saving functionality (no more copying to separate note apps)
- Clean chat organization

## The Technical Deep Dive

### Performance Optimization: From 2.8s to 83ms

The biggest technical challenge was rendering performance. Like most AI chat apps, Withsy became sluggish as conversations grew longer. Even after page refresh, the markdown rendering would freeze the interface.

Here's how I tackled it:

**1. Smart Component Memoization**
```typescript
const ChatBubble = memo(ChatBubbleComponent, (prevProps, nextProps) => {
  return prevProps.id === nextProps.id &&
         prevProps.isBookmarked === nextProps.isBookmarked &&
         prevProps.text === nextProps.text &&
         prevProps.status === nextProps.status;
});
```

**2. Optimized DOM References**
```typescript
// Efficient message scrolling without re-rendering everything
<div ref={(el) => { messageRefs.current[msg.id] = el }}>
```

**3. Conditional Rendering**
- Messages over 150 characters are collapsed by default
- Reasoning text only renders when requested
- Smart auto-scroll that respects user's scroll position

**4. Lazy Loading Strategy**
Only render visible content and reasoning text on demand.

**Result**: Chat loading time dropped from 2.8 seconds to 83ms—a 97% improvement.

### Multi-Model Integration

One unexpected benefit was implementing multi-model support within single conversations. Users could ask Grok a question, then get Gemini's perspective on the same topic without losing context or switching chats.

Most AI SDKs follow OpenAI's standard, making integration straightforward (except Google's Gemini, which required their specific SDK). The ecosystem is consolidating nicely.

## Tech Stack Choices

**Next.js Full-Stack**: Not my preferred architecture (I find Next.js backend debugging frustrating), but budget constraints meant single-server deployment. As always, **infrastructure decisions come down to money**.

**PostgreSQL**: Reliable choice for the relational data patterns (chats, branches, users, messages).

**Why Next.js for Frontend**: Despite my backend reservations, Next.js remains my go-to for complex, app-like interfaces. Development speed was crucial for this side project.

## Lessons Learned

### Feature Creep is Real
I initially built thread functionality (thinking it would be useful like Slack threads) and tab organization (like Notion). Both got deprecated because:
- Branch functionality covered thread use cases
- Star system made tabs redundant
- Complexity hurt the core user experience

**Lesson**: Simplicity wins. Features that seem obviously useful often aren't.

### The Product-Market Fit Reality
Building something because "wouldn't this be nice?" isn't enough. Coming from corporate development where every feature solves a specific problem, I realized personal projects need the same problem-solving focus to gain traction.

**Who might actually use Withsy?**
- Power users who want to save and organize chat messages
- Users who demand prompt transparency
- People frustrated with platform limitations of major providers

But reaching these users would require integrating with ChatGPT and Claude APIs—financially unfeasible at current scale.

## The Honest Assessment

Withsy scratches my personal itches perfectly, but that's not enough for a sustainable product. The major AI platforms are improving rapidly and offering generous free tiers. Unless you're solving a problem that keeps users awake at night, "nice to have" features won't drive adoption.

That said, building Withsy was incredibly valuable:
- **Performance optimization skills** from the markdown rendering challenge
- **Product thinking** about feature necessity vs. feature creep  
- **Technical exploration** of the AI ecosystem's current state
- **Honest evaluation** of personal projects vs. market needs

## What's Next

Withsy remains my personal AI chat platform of choice, and I'll continue using and refining it. The codebase serves as a solid foundation for future AI-related experiments.

For developers considering similar projects: build for the learning, not just the outcome. Sometimes the most valuable product insights come from products that don't quite make it to market.
