---
title: "Fighting Notification Spam: Two Real-World Case Studies in Building Better Alerts"
description: "Learn how thoughtful notification design can transform team productivity through two real-world experiences - from reducing QA overhead in game engine development to streamlining deployment workflows. Discover practical strategies to make alerts actionable, contextual, and actually useful."
tags: [
  "devops",
  "sre",
  "ci-cd",
  "monitoring",
  "alerting",
  "notification-design",
  "alert-fatigue",
  "jenkins",
  "process-improvement",
  "productivity",
  "engineering-culture",
  "deployment-automation",
  "game-development"
]
date: "2025-04-03"
---


## How Better Notifications Saved 60% of Our Engineering Resources

What if I told you that redesigning notification systems helped my teams:
- **Eliminate an entire manual QA process** that was consuming hours daily
- **Reduce release engineering headcount from 10 to 4 people** while handling 50% more deployments
- **Increase monthly deployment capacity from 1,000 to 1,500** with fewer resources

Sound too good to be true? Here's the catch: we didn't add new tools or hire more people. We just made existing information **convenient** to act on.

How many times have you missed a critical alert because it was buried under routine notifications? Or found yourself ignoring alerts because most turned out to be irrelevant noise? Alert fatigue affects 28% of teams, causing them to forget to review critical alerts.

The problem isn't just notification volume - it's that we fundamentally misunderstand what makes alerts effective. Over the years, I've learned a crucial lesson that now guides my engineering approach: **Having information doesn't solve the problem. Being able to do something doesn't solve the problem. It has to be convenient.**

Let me share two real experiences where this principle transformed our team productivity.

## Case Study 1: From Manual QA Processes to Automated Performance Alerts

### The Initial Challenge

At my first company, we developed games using a proprietary game engine rather than commercial ones like Unreal or Unity. Performance was absolutely critical - every commit could potentially impact the engine's efficiency, affecting all games built on top of it.

Initially, our performance testing workflow looked like this:
- Developers committed code to the engine
- QA team manually triggered performance tests
- After tests completed, QA analyzed logs and version control history
- QA manually identified which commits caused performance regressions  
- QA reached out to individual developers to investigate issues

This process consumed significant QA resources that should have been focused on actual game testing rather than detective work.

### The First Iteration: Automated but Noisy

I built an automated system that:
- Triggered performance tests on every commit
- Queued commits during test execution to batch them efficiently
- Automatically tagged developers when their commits caused performance issues
- Included detailed logs and performance data in notifications

Initially, everyone loved it. We eliminated a major manual process from the QA team's workload. But soon, new problems emerged:

- **Alert storm**: Continuous notifications until issues were resolved created fatigue
- **Context switching**: Important alerts got buried under new ones
- **Analysis paralysis**: Developers had to interpret raw logs and performance data
- **State confusion**: People didn't know if someone was already working on an issue

The information was there, but it wasn't convenient to act on.

### The Solution: Contextual and Stateful Notifications

I redesigned the system with these key improvements:

**Thread-based state tracking**: Instead of sending new alerts for the same issue, the system updated existing alert threads with new occurrences. This kept all context in one place and prevented important discussions from being scattered.

**Performance context**: Rather than just showing raw numbers, I integrated with Elasticsearch to compare current performance against historical baselines. Notifications now showed intuitive comparisons like "+15% slower" or "execution time increased by 2.3 seconds" with clear visual indicators.

**Smart deduplication**: The system maintained a database of active issues and only created new alert threads for genuinely new problems.

### The Impact

This wasn't just about better notifications - it fundamentally changed how our team worked. The QA team could focus entirely on game testing instead of performance investigation. Developers got actionable information without needing to dig through logs. Most importantly, performance issues were resolved faster because the right context was immediately available.

## Case Study 2: Transforming Deployment Chaos into Streamlined Communication

### The Existing Problem

My second company had an elaborate deployment pipeline using Jenkins and Spinnaker, with the DevOps team dutifully sending notifications for every status change. But here's what I discovered when I surveyed developers: most didn't even know these notifications existed.

The deployment process required full-time monitoring:
- 10 release engineers constantly checking Jenkins and Spinnaker dashboards
- Manual status updates shared in chat rooms
- Developers unable to check deployment status remotely (access restrictions)
- Operators spending entire days just polling deployment tools

I realized we had a classic case of information existing but not being convenient. The DevOps team was sending notifications, but they were essentially spam:
- Too many parallel alerts made it impossible to track individual deployments
- No way to identify which deployment belonged to which developer
- Status updates were disconnected from each other
- No clear indication of what action (if any) was required

### Redesigning for User Experience

After convincing the DevOps team to add Jenkins build IDs to their notifications, I rebuilt the entire alert system around user needs:

**Deployment-centric threads**: Each deployment got its own message thread, starting when the build began and updating throughout the process.

**Smart recipient targeting**: Only the requesting developer and assigned operator were tagged, reducing noise for everyone else.

**Consolidated status tracking**: All updates (build status, deployment progress, completion) appeared as threaded replies to the original message.

**Context-rich information**: Each notification included what was being deployed, current status, and what (if anything) the recipient needed to do next.

### The Transformation

The results were dramatic:
- **Team size**: Reduced from 10 full-time release engineers to 1 full-time + 3 part-time operators
- **Deployment volume**: Increased from 1,000 to 1,500 deployments per month
- **Developer experience**: Teams could track deployments remotely through Slack alone
- **Operator efficiency**: No more constant dashboard polling - they only acted when notified

This wasn't just process optimization; it was a fundamental shift in how information flowed through our organization.

## Key Principles for Effective Notifications

Both experiences taught me that good notifications aren't just about having the right information - they're about presenting it in a way that makes the right action obvious and easy.

### 1. Design from the Recipient's Perspective

Don't just think about what information you need to send. Consider:
- What does the recipient need to know?
- What action (if any) should they take?
- What context do they need to take that action efficiently?

### 2. Consolidate Related Information

Scattered notifications create cognitive overhead. Use threading, grouping, or other mechanisms to keep related updates together. This prevents important context from being lost and reduces notification fatigue.

### 3. Make Actions Obvious

If your notification requires action, make it crystal clear what that action is. If it's purely informational, make that obvious too. Ambiguous notifications train people to ignore alerts.

### 4. Provide Sufficient Context

Raw data isn't actionable. Transform information into insights. Instead of "CPU usage: 85%", consider "CPU usage 15% above normal baseline - investigation recommended."

### 5. Prevent Notification Storms

Build intelligence into your alerting system. Group similar issues, prevent duplicate alerts for the same problem, and consider the cumulative impact of multiple notifications on the same recipient.

## The Broader Impact

Both cases demonstrate something crucial: well-designed notifications can eliminate entire categories of manual work. In the first case, we freed up QA resources for actual testing. In the second, we reduced a 10-person monitoring operation to 4 people while handling 50% more volume.

This isn't just about notifications - it's about recognizing that having the capability to access information isn't the same as having convenient access to actionable insights.

The principle that guides my engineering decisions is simple: **Information existing doesn't solve the problem. Being technically possible doesn't solve the problem. It has to be convenient.**

When we design systems - whether they're notifications, APIs, or user interfaces - convenience should be a first-class consideration, not an afterthought. Because ultimately, the most technically sophisticated solution is worthless if people find it easier to work around it than with it.
